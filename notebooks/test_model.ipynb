{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3348ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"..\")  # Navigate to the parent directory to access src module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902cee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import ResNet\n",
    "\n",
    "# Path to your saved model\n",
    "# model_path = \"/home/zakarianarjis/workspace/recursive-reasoning/experiments/ResNet_CIFAR100_2025-11-17_15-52-31/best_model.pth\" # recursive mode false \n",
    "model_path = \"/home/zakarianarjis/workspace/recursive-reasoning/experiments/ResNet_CIFAR100_2025-11-14_21-30-45/best_model.pth\" # recursive mode true Nsup 8 , Nlatent 6, Ndeep 3\n",
    "# Create model with the right arguments (adjust if needed)\n",
    "model = ResNet(\n",
    "    num_classes=100,\n",
    "    recursive_mode=True,\n",
    "    pretrained=True,\n",
    "    use_precomputed_features=True\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "state_dict = torch.load(model_path, map_location=\"cuda\" )\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2398406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "path = \"/scratch/narjis/CIFAR100/precomputed_embeding/train.pt\"\n",
    "\n",
    "data = torch.load(path)      # load the tensor/list/dict\n",
    "one_feature = data['features'][0].reshape(1, -1)  # get the first feature and reshape to (1, feature_dim)\n",
    "embed_out = model.get_input_embedding(one_feature.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "620044cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan, 1.7717, 1.9903, 1.8971, 1.9694,    nan, 1.9483,    nan,    nan,\n",
       "         1.9555, 1.9457,    nan, 1.8154,    nan, 1.9813,    nan, 1.6178, 1.8746,\n",
       "            nan,    nan,    nan,    nan,    nan, 1.9893, 1.9451,    nan,    nan,\n",
       "            nan, 1.8789,    nan, 1.8848,    nan,    nan,    nan,    nan,    nan,\n",
       "            nan, 1.9757, 0.9263,    nan, 1.8442, 0.0000,    nan, 1.6641, 1.9921,\n",
       "            nan,    nan,    nan, 1.7138, 1.9808, 1.9972,    nan, 1.9335, 1.9805,\n",
       "            nan, 1.9783, 1.9570, 1.8617,    nan, 1.8871, 1.9678,    nan, 1.9846,\n",
       "            nan,    nan, 2.0676,    nan, 1.8821,    nan, 1.9815, 1.9599, 1.9596,\n",
       "         1.9669,    nan,    nan,    nan,    nan,    nan, 1.9880, 1.9735, 2.0854,\n",
       "            nan,    nan,    nan,    nan, 1.9458,    nan,    nan, 1.9836, 1.9318,\n",
       "            nan, 2.5214,    nan,    nan,    nan, 1.9867,    nan, 2.0012,    nan,\n",
       "            nan,    nan,    nan, 1.9754, 1.9816,    nan,    nan, 1.8740, 1.9644,\n",
       "            nan, 1.9924, 1.9867,    nan, 2.4687, 1.9265,    nan, 2.0411, 2.0670,\n",
       "            nan,    nan, 1.9557, 1.9561,    nan,    nan, 1.9778,    nan, 1.9530,\n",
       "         1.9850, 1.8021, 1.9823, 1.9995,    nan,    nan, 1.9436,    nan,    nan,\n",
       "         1.9660, 1.9743,    nan,    nan, 1.9484,    nan, 1.9651, 1.9981, 2.0033,\n",
       "         1.9603,    nan, 1.9370,    nan,    nan, 1.9767,    nan, 1.9806, 1.9595,\n",
       "            nan, 1.6485, 1.9930, 1.9877,    nan,    nan,    nan, 1.9724, 1.6056,\n",
       "         1.9735, 1.9742,    nan,    nan, 1.9878, 2.0031,    nan,    nan,    nan,\n",
       "            nan,    nan,    nan,    nan, 2.2695, 1.9707, 1.9706,    nan, 2.1515,\n",
       "            nan, 1.9221,    nan, 1.9339, 1.9560,    nan, 1.9682,    nan, 1.9390,\n",
       "         1.9718, 2.0201, 1.9568, 1.9954,    nan, 1.8841, 1.9812,    nan,    nan,\n",
       "            nan,    nan,    nan, 1.8386, 1.9763,    nan, 1.9492, 1.9755,    nan,\n",
       "            nan, 1.9854, 1.9698, 1.9576, 1.9095,    nan,    nan,    nan,    nan,\n",
       "            nan,    nan,    nan, 2.0154,    nan,    nan,    nan, 2.0175,    nan,\n",
       "            nan, 1.7874,    nan,    nan,    nan,    nan, 2.0052,    nan,    nan,\n",
       "         1.9802, 1.9628,    nan, 1.9820,    nan,    nan,    nan, 1.8158,    nan,\n",
       "            nan, 1.9882,    nan, 1.9957,    nan, 1.9932, 1.8962,    nan,    nan,\n",
       "         2.0015,    nan, 1.9602,    nan, 1.9340, 2.0088,    nan,    nan, 2.0037,\n",
       "         1.9906,    nan,    nan,    nan, 1.9579, 1.9354,    nan, 1.9989, 1.9021,\n",
       "            nan, 1.9490,    nan, 1.9732, 1.9480, 1.9896, 1.9690,    nan,    nan,\n",
       "         1.8939,    nan, 1.9896, 1.9806,    nan, 1.9403, 1.9871, 1.9247,    nan,\n",
       "         1.9563, 1.9907, 1.9758,    nan, 1.9871, 2.0329,    nan, 1.9763,    nan,\n",
       "            nan,    nan, 1.9284, 1.8973, 2.0189, 1.9883, 2.0043,    nan,    nan,\n",
       "         1.9369,    nan,    nan,    nan,    nan,    nan, 1.8901,    nan,    nan,\n",
       "         1.9437,    nan,    nan,    nan,    nan,    nan, 1.9318, 1.8454,    nan,\n",
       "         1.9375, 1.9222,    nan, 1.9661, 1.8811,    nan,    nan, 1.9601, 1.9360,\n",
       "            nan,    nan,    nan,    nan, 1.9857, 1.8893, 1.9722,    nan,    nan,\n",
       "            nan, 1.8437,    nan,    nan,    nan, 1.9559,    nan, 1.9882, 1.9365,\n",
       "         1.9743, 1.9225, 1.9823, 1.9702,    nan,    nan, 1.9593,    nan, 1.9535,\n",
       "         1.9648,    nan, 1.9710,    nan,    nan, 1.9713,    nan,    nan,    nan,\n",
       "         1.9015,    nan, 1.9573,    nan,    nan, 1.9731,    nan, 2.0091,    nan,\n",
       "            nan,    nan,    nan, 1.9598,    nan,    nan, 1.9742,    nan, 1.9380,\n",
       "         1.8319, 1.9835,    nan, 2.0270,    nan, 1.9107, 1.9856, 1.9887,    nan,\n",
       "         1.9928,    nan, 1.9647,    nan, 1.9559,    nan, 2.0078, 1.9644,    nan,\n",
       "         2.0049, 1.9775, 1.8024, 2.0004, 1.9657,    nan, 1.8724,    nan,    nan,\n",
       "         1.9223, 1.9342, 2.0183, 1.6846, 1.5405, 1.8627, 2.0017, 1.9562,    nan,\n",
       "            nan, 1.9044,    nan,    nan, 1.9622, 1.9988, 1.9884, 1.8331, 1.9726,\n",
       "            nan, 1.9715,    nan, 1.9576,    nan, 1.9361,    nan, 1.9955,    nan,\n",
       "         1.9671, 2.0003, 1.9735,    nan, 1.9115,    nan,    nan, 1.9172,    nan,\n",
       "         1.9066, 1.9506,    nan,    nan, 1.9779, 1.9735, 1.9652, 1.5719,    nan,\n",
       "         1.9772,    nan,    nan,    nan, 2.1133,    nan,    nan, 1.9310, 0.8934,\n",
       "            nan,    nan,    nan,    nan,    nan,    nan, 1.9865,    nan,    nan,\n",
       "         1.9753, 1.9844, 1.9857,    nan,    nan, 1.9912,    nan, 2.0054,    nan,\n",
       "            nan, 1.9325,    nan,    nan,    nan,    nan, 1.9542,    nan, 2.0138,\n",
       "            nan,    nan,    nan,    nan,    nan, 1.9202,    nan, 1.9864, 1.9975,\n",
       "         1.9771,    nan, 0.0000, 1.8956,    nan,    nan, 1.9315,    nan]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1 = model.backbone(2*embed_out)\n",
    "output_2 = model.backbone(embed_out)\n",
    "output_1/output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25381ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error between MLP and best-fit linear model = 0.004029848147183657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004029848147183657"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def check_linear_behavior(model, input_dim, num_samples=5000):\n",
    "    model.eval()\n",
    "    x = torch.rand(num_samples, input_dim)\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "\n",
    "    # Fit a linear model: y â‰ˆ Ax + b\n",
    "    linear = nn.Linear(input_dim, y.shape[1], bias=True)\n",
    "    optimizer = torch.optim.LBFGS(linear.parameters(), max_iter=500)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = linear(x)\n",
    "        loss = ((pred - y)**2).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    # Evaluate how well the linear layer approximates the MLP\n",
    "    with torch.no_grad():\n",
    "        pred = linear(x)\n",
    "        error = ((pred - y)**2).mean().sqrt().item()\n",
    "\n",
    "    print(\"RMS error between MLP and best-fit linear model =\", error)\n",
    "    return error\n",
    "check_linear_behavior(model.backbone.cpu(), input_dim=512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kimeko",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
